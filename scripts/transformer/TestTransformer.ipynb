{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Notebook to test trained transformer (Chignolin) and generated components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "from utils import Transformer\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_network_folder_name = \"./ChignolinGMMTransformerTraining/\"\n",
    "root_dataset_folder_name = \"./ChignolinGMMTransformerDataset/\"\n",
    "\n",
    "all_num_components_by_res_num = np.load(f\"{root_dataset_folder_name}all_num_components.npy\", allow_pickle=True).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dim_model = 256\n",
    "dropout_p = 0.1\n",
    "kt_cutoff = -50\n",
    "beta_target = 1.0\n",
    "epoch_num = 14\n",
    "\n",
    "network_folder_name = f\"{root_network_folder_name}dropout_p_{dropout_p}_dim_model_{dim_model}_kt_cutoff_{kt_cutoff}/\"\n",
    "\n",
    "t = Transformer(num_tokens_src=7, num_tokens_tgt=67,\n",
    "                dim_model=dim_model, num_heads=8, num_encoder_layers=6,\n",
    "                num_decoder_layers=6, dropout_p=dropout_p).to(device)\n",
    "t.load_state_dict(torch.load(f\"{network_folder_name}t_{epoch_num}.pt\"))\n",
    "t.eval()\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "dataset_tag = f\"prop_temp_300.0_dt_0.001_num_steps_5_cutoff_to_use_kt_{kt_cutoff}\"\n",
    "dataset_folder_name = f\"{root_dataset_folder_name}{dataset_tag}/\"\n",
    "all_backbone_indices = os.listdir(f\"{dataset_folder_name}/test\")\n",
    "all_backbone_indices = np.unique([f.split(\"_\")[0] \n",
    "                                  for f in all_backbone_indices])\n",
    "\n",
    "\n",
    "save_folder_name = f\"{dataset_tag}/test/\"\n",
    "os.makedirs(save_folder_name, exist_ok=True)\n",
    "\n",
    "test_all_src_cat = torch.tensor(np.load(f\"{dataset_folder_name}test_all_src_cat.npy\"), \n",
    "                                 device=device)[0:100000]\n",
    "all_pred_sizes = []\n",
    "for backbone_index in all_backbone_indices:\n",
    "    all_c_info = np.load(f\"{dataset_folder_name}test/{backbone_index}_c_info.npy\")\n",
    "    all_src_cont = np.stack((np.sin(all_c_info[:, :, 0]),\n",
    "                             np.cos(all_c_info[:, :, 0]),\n",
    "                             np.sin(all_c_info[:, :, 1]),\n",
    "                             np.cos(all_c_info[:, :, 1])), axis=-1)\n",
    "    all_src_cont = torch.tensor(all_src_cont, device=device).float()\n",
    "    all_src_cont = all_src_cont.repeat((100, 1, 1))\n",
    "    all_src_cat = test_all_src_cat[0:all_src_cont.shape[0]]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pred_components = torch.tensor([[65]],\n",
    "                                       device=device).repeat((all_src_cat.shape[0], 1)).long()\n",
    "        for _ in range(13):\n",
    "            tgt_mask = t.get_tgt_mask(pred_components.shape[1]).to(device)\n",
    "            pred = t(src_cont=all_src_cont,\n",
    "                    src_cat = all_src_cat,\n",
    "                    tgt=pred_components, tgt_mask=tgt_mask)[:, -1, :]\n",
    "            pred = nn.Softmax(dim=-1)(pred)\n",
    "            next_item = torch.multinomial(pred, 1, replacement=True)\n",
    "            pred_components = torch.cat((pred_components, \n",
    "                                        next_item), dim=-1)\n",
    "        correct_sequences = ((~torch.any(pred_components[:, :13] == 66, dim=-1))\n",
    "                            & (pred_components[:, -1] == 66))\n",
    "\n",
    "        pred_components = pred_components[correct_sequences][:, 1:-1]\n",
    "        \n",
    "        all_allowed = torch.ones_like(pred_components[:, 0]).bool()\n",
    "        for (res_num, num_components) in all_num_components_by_res_num.items():\n",
    "            all_allowed = all_allowed * (pred_components[:, res_num] < num_components)\n",
    "\n",
    "        pred_components_filtered = pred_components[all_allowed]\n",
    "        for (res_num, num_components) in all_num_components_by_res_num.items():\n",
    "            assert torch.max(pred_components_filtered[:, res_num]) < num_components\n",
    "    \n",
    "    torch.save(pred_components_filtered, f\"{save_folder_name}{backbone_index}_pred_components.pt\")\n",
    "    all_pred_sizes.append(pred_components_filtered.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./all_pred_sizes.npy\", np.array(all_pred_sizes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cgpomm]",
   "language": "python",
   "name": "conda-env-cgpomm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
